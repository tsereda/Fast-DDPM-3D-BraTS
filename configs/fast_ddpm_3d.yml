# Updated Fast-DDPM 3D Configuration following professor's recommendations
# 4 input modalities â†’ 1 target modality synthesis

data:
    dataset: "BraTS3D"
    crop_size: [64, 64, 64]   
    crops_per_volume: 4    
    channels: 1    
    num_workers: 4
    normalization: "min_max_0_1" # Professor: Min-max normalization to [0,1]

model:
    type: "unified_4to1"     # 4 input modalities â†’ 1 target modality
    in_channels: 4           # Input: all 4 BraTS modalities
    out_ch: 1               # Output: single target modality
    ch: 32                  # ðŸ”¥ FIXED: Reduced from 64 to 32 for stability (~15M parameters)
    ch_mult: [1, 2]         # ðŸ”¥ FIXED: Reduced from [1, 2, 4] to [1, 2] 
    num_res_blocks: 1       # ðŸ”¥ FIXED: Reduced from 2 to 1 block per level
    attn_resolutions: []    # ðŸ”¥ FIXED: Removed attention for stability
    dropout: 0.1
    var_type: fixedsmall    # Fixed variance (not learned)
    ema_rate: 0.9999        # Exponential moving average
    ema: True
    resamp_with_conv: True  # Use conv for up/downsampling
    use_sigmoid: False      # ðŸ”¥ FIXED: No sigmoid for diffusion models

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.01                 # Reduced from 0.02 for gentler diffusion
    num_diffusion_timesteps: 1000

training:
    batch_size: 1                 # Can be larger with cropping
    gradient_accumulation_steps: 2   # Effective batch size = batch_size * gradient_accumulation_steps
    epochs: 1000
    learning_rate: 0.00001         # ðŸ”¥ FIXED: Reduced from 0.0002 to 1e-5 for 3D stability
    weight_decay: 0.0
    gradient_clip: 0.1             # ðŸ”¥ FIXED: Much stricter gradient clipping
    loss_type: "mse"               # Professor: Use MSE loss
    
    # Checkpointing
    save_every: 2000                # Save every 2000 steps
    validate_every: 1000            # Validate every 1000 steps
    log_every_n_steps: 50           # Log progress every 50 steps

optim:
    optimizer: "Adam"
    lr: 0.00001                    # ðŸ”¥ FIXED: Match training.learning_rate (1e-5)
    beta1: 0.9
    weight_decay: 0.0
    amsgrad: false
    eps: 0.00000001

# Sampling configuration
sampling:
    timesteps: 10                   # Fast-DDPM: only 10 steps
    scheduler_type: "uniform"       # or "non-uniform"
    eta: 0.0                       # DDIM parameter
    batch_size: 1
    
    # Noise initialization for [0,1] range
    init_type: "gaussian"          # Use Gaussian noise
    noise_std: 0.5                 # Reduced std for [0,1] range
    noise_mean: 0.5                # Center noise in [0,1] range

# Device and precision
device: "cuda"
mixed_precision: True              # Enable for memory efficiency