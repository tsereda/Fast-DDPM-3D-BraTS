data:
    dataset: "BraTS3D"
    volume_size: [64, 64, 64]  # Reduced from 80 for memory safety
    channels: 1
    num_workers: 4

model:
    type: "unified_4to1"  # Corrected: 4 input modalities â†’ 1 target modality
    in_channels: 4        # Input: all 4 modalities
    out_ch: 1            # Output: single target modality
    ch: 64               # Reduced for 3D memory constraints
    ch_mult: [1, 2, 4]   # Reduced depth for 3D
    num_res_blocks: 2
    attn_resolutions: [16]  # Adjusted for 64x64x64 volumes
    dropout: 0.1
    var_type: fixedsmall
    ema_rate: 0.9999
    ema: True
    resamp_with_conv: True

diffusion:
    beta_schedule: linear
    beta_start: 0.0001
    beta_end: 0.02
    num_diffusion_timesteps: 1000

training:
    batch_size: 1        # Small batch size for 3D
    epochs: 1000
    learning_rate: 0.0001 
    weight_decay: 0.0
    gradient_clip: 1.0
    save_every: 2000     # Save checkpoint every 2000 training steps (less frequent)
    validate_every: 1000 # Validate every 1000 training steps
    log_every_n_steps: 50
    # Gradient accumulation will be controlled via command line argument
    
    # Loss scaling settings for stability
    loss_scale_init: 2048.0    # Initial loss scale (lower than default 65536)
    loss_scale_growth: 2000    # Steps between scale increases
    loss_scale_backoff: 0.5    # Scale reduction factor on overflow
    
optim:
    weight_decay: 0.0
    optimizer: "Adam"
    lr: 0.00001  # REDUCED from 0.0001
    beta1: 0.9
    amsgrad: false
    eps: 0.00000001

# Additional stability settings
stability:
    warmup_steps: 1000          # Gradual learning rate warmup
    memory_cleanup_interval: 100 # Clear GPU cache every N steps
    nan_check_interval: 50      # Check for NaN values in loss/gradients