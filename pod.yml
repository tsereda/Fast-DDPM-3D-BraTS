apiVersion: v1
kind: Pod
metadata:
  name: tsereda-brats-pod
  labels:
    app: fast-ddpm-brats
spec:
  securityContext:
    fsGroup: 0
  nodeSelector:
    topology.kubernetes.io/region: us-west
  containers:
    - name: brats-processing
      image: gitlab-registry.nrp-nautilus.io/prp/jupyter-stack/prp
      env:
        - name: REPO_PATH
          value: /app/Fast-DDPM-3D-BraTS
        - name: SYNAPSE_AUTHTOKEN
          valueFrom:
            secretKeyRef:
              name: synapse-credentials
              key: authtoken
              optional: true
        - name: PYTHONPATH
          value: /app/Fast-DDPM-3D-BraTS
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: PYTORCH_CUDA_ALLOC_CONF
          value: "max_split_size_mb:512"
        - name: OMP_NUM_THREADS
          value: "4"
        - name: MKL_NUM_THREADS
          value: "4"
      command:
        - "bash"
        - "-c"
      args:
        - |
          set -e  # Exit on any error
          
          # Memory monitoring function
          monitor_memory() {
            local step="$1"
            echo "üíæ Memory at $step: $(free -h | grep Mem | awk '{print "Used: "$3"/"$2" ("$3/$2*100"%)"}') "
            # Kill process if memory usage is too high (>85% for 32GB limit)
            local mem_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
            if [ "$mem_usage" -gt 85 ]; then
              echo "‚ö†Ô∏è Memory usage critical: ${mem_usage}% - forcing aggressive cleanup"
              # Clear all possible caches
              sync && echo 3 > /proc/sys/vm/drop_caches 2>/dev/null || true
              python -c "import gc; gc.collect()" 2>/dev/null || true
              # Clear pip cache
              pip cache purge 2>/dev/null || true
              # Clear conda cache
              conda clean --all -y 2>/dev/null || true
            fi
          }
          
          echo "üöÄ Starting Fast-DDPM-3D-BraTS Setup..."
          monitor_memory "startup"
          
          # Create checkpoint directory
          mkdir -p /tmp/setup_checkpoints
          
          # Update system packages
          if [ ! -f "/tmp/setup_checkpoints/packages_updated" ]; then
            echo "üì¶ Updating system packages..."
            monitor_memory "before package update"
            sudo apt-get update && sudo apt-get install -y p7zip-full wget git vim htop
            touch /tmp/setup_checkpoints/packages_updated
            monitor_memory "after package update"
          else
            echo "‚úì System packages already updated"
          fi
          
          # Clone repository
          if [ ! -f "/tmp/setup_checkpoints/repo_cloned" ]; then
            echo "üìÇ Cloning repository..."
            if [ ! -d "${REPO_PATH}" ]; then
              git clone https://github.com/tsereda/Fast-DDPM-3D-BraTS.git ${REPO_PATH}
            fi
            touch /tmp/setup_checkpoints/repo_cloned
          else
            echo "‚úì Repository already cloned"
          fi
          cd ${REPO_PATH}
          
          # Check disk usage before data extraction
          echo "üìÅ Current disk usage:"
          echo "  /app: $(du -sh /app 2>/dev/null || echo "N/A")"
          echo "  /data: $(du -sh /data 2>/dev/null || echo "N/A")"
          echo "  Available space: $(df -h /app | tail -1 | awk '{print $4}')"
          
          # Check for data files
          echo "üìä Checking for data files..."
          if [ -f "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData.zip" ] && [ ! -f "/tmp/setup_checkpoints/training_data_extracted" ]; then
            echo "‚úì Found training data"
            echo "üì¶ Extracting training data directly to /data (no copy)..."
            cd /data
            7z x ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData.zip -y -mmt=$(nproc) || {
              echo "‚ö†Ô∏è Training data extraction failed, continuing without it"
            }
            # Create symlink to avoid copying large files
            cd ${REPO_PATH}
            if [ -d "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData" ]; then
              ln -sf /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData ./ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData
            fi
            touch /tmp/setup_checkpoints/training_data_extracted
          elif [ -f "/tmp/setup_checkpoints/training_data_extracted" ]; then
            echo "‚úì Training data already extracted"
            cd ${REPO_PATH}
            # Ensure symlink exists
            if [ -d "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData" ] && [ ! -e "./ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData" ]; then
              ln -sf /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData ./ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData
            fi
          else
            echo "‚ö†Ô∏è Training data not found in /data/"
          fi
          
          if [ -f "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData.zip" ] && [ ! -f "/tmp/setup_checkpoints/validation_data_extracted" ]; then
            echo "‚úì Found validation data"
            echo "üì¶ Extracting validation data directly to /data (no copy)..."
            cd /data
            7z x ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData.zip -y -mmt=$(nproc) || {
              echo "‚ö†Ô∏è Validation data extraction failed, continuing without it"
            }
            # Create symlink to avoid copying large files
            cd ${REPO_PATH}
            if [ -d "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData" ]; then
              ln -sf /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData ./ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData
            fi
            touch /tmp/setup_checkpoints/validation_data_extracted
          elif [ -f "/tmp/setup_checkpoints/validation_data_extracted" ]; then
            echo "‚úì Validation data already extracted"
            cd ${REPO_PATH}
            # Ensure symlink exists
            if [ -d "/data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData" ] && [ ! -e "./ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData" ]; then
              ln -sf /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData ./ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData
            fi
          else
            echo "‚ö†Ô∏è Validation data not found in /data/"
          fi
          
          # Setup environment
          if [ ! -f "/tmp/setup_checkpoints/environment_setup" ]; then
            echo "üêç Setting up Python environment..."
            echo "üíæ Memory before environment setup: $(free -h | grep Mem)"
            cd ${REPO_PATH}
            
            # Add error handling for container runtime issues
            echo "üîç Checking container runtime..."
            if ! command -v conda &> /dev/null; then
              echo "‚ùå Conda not found, installing miniconda..."
              wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
              bash miniconda.sh -b -p /opt/miniconda
              export PATH="/opt/miniconda/bin:$PATH"
              rm miniconda.sh
            fi
            
            # Initialize conda with retry mechanism
            echo "üîÑ Initializing conda..."
            for i in {1..3}; do
              if eval "$(conda shell.bash hook)" 2>/dev/null; then
                echo "‚úì Conda initialized successfully"
                break
              else
                echo "‚ö†Ô∏è Conda initialization attempt $i failed, retrying..."
                sleep 5
              fi
            done
            
            # Check if environment exists with retry
            echo "üîç Checking for existing environment..."
            if conda env list | grep -q "brasyn" 2>/dev/null; then
              echo "‚úì Environment brasyn already exists, activating..."
              conda activate brasyn || {
                echo "‚ö†Ô∏è Failed to activate existing environment, recreating..."
                conda env remove -n brasyn -y 2>/dev/null || true
              }
            fi
            
            # Create environment if it doesn't exist or activation failed
            if ! conda env list | grep -q "brasyn" 2>/dev/null; then
              echo "üîß Creating brasyn environment..."
              if [ -f "environment.yml" ]; then
                # Try with conda with memory optimization - create minimal environment instead
                echo "Creating minimal environment due to memory constraints..."
                conda create -n brasyn python=3.11 -y
                conda activate brasyn
                # Install only essential packages for minimal environment
                pip install torch --index-url https://download.pytorch.org/whl/cu118 --no-cache-dir
                pip install numpy nibabel tqdm --no-cache-dir
              else
                echo "‚ö†Ô∏è environment.yml not found, creating minimal environment..."
                conda create -n brasyn python=3.11 -y
              fi
              
              # Activate the newly created environment
              conda activate brasyn || {
                echo "‚ùå Failed to activate environment, using base environment"
                export CONDA_DEFAULT_ENV=base
              }
            fi
              
            # Install essential packages with retries and memory optimization
            echo "üì¶ Installing essential packages with aggressive memory management..."
            
            # Set pip cache to /tmp to avoid disk space issues
            export PIP_CACHE_DIR=/tmp/pip-cache
            mkdir -p $PIP_CACHE_DIR
            
            # Install packages one by one with very conservative approach
            declare -a essential_packages=(
              "SimpleITK"
              "PyYAML"
              "matplotlib"
              "scipy"
              "pandas"
              "opencv-python"
              "scikit-image"
            )
            
            declare -a optional_packages=(
              "gdown"
              "wandb"
              "lpips"
              "einops"
              "accelerate"
            )
            
            # Install essential packages first
            for package in "${essential_packages[@]}"; do
              echo "Installing essential: $package"
              for attempt in {1..2}; do
                # Clear caches before each attempt
                rm -rf $PIP_CACHE_DIR/*
                pip cache purge 2>/dev/null || true
                python -c "import gc; gc.collect()" 2>/dev/null || true
                
                if timeout 300 pip install $package --no-cache-dir --timeout 180; then
                  echo "‚úì Successfully installed: $package"
                  break
                else
                  echo "‚ö†Ô∏è Attempt $attempt failed for: $package"
                  if [ $attempt -eq 2 ]; then
                    echo "‚ùå Failed to install: $package (continuing anyway)"
                  fi
                fi
              done
              
              # Check memory after each package
              monitor_memory "after installing $package"
              sleep 3
            done
            
            # Install optional packages only if memory allows
            local mem_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
            if [ "$mem_usage" -lt 75 ]; then
              echo "üì¶ Installing optional packages..."
              for package in "${optional_packages[@]}"; do
                echo "Installing optional: $package"
                # Single attempt for optional packages
                if timeout 300 pip install $package --no-cache-dir --timeout 180; then
                  echo "‚úì Successfully installed: $package"
                else
                  echo "‚ö†Ô∏è Failed to install optional package: $package (skipping)"
                fi
                monitor_memory "after installing optional $package"
                sleep 2
              done
            else
              echo "‚ö†Ô∏è Skipping optional packages due to memory constraints (${mem_usage}%)"
            fi
            
            # Final cleanup
            rm -rf $PIP_CACHE_DIR
            pip cache purge 2>/dev/null || true
            conda clean --all -y 2>/dev/null || true
            python -c "import gc; gc.collect()" 2>/dev/null || true
            monitor_memory "after all package installation"
            
            touch /tmp/setup_checkpoints/environment_setup
            monitor_memory "environment setup complete"
          else
            echo "‚úì Python environment already set up"
            cd ${REPO_PATH}
            eval "$(conda shell.bash hook)" 2>/dev/null || true
            conda activate brasyn 2>/dev/null || true
          fi
          
          # Verify environment and system health
          echo "üîç Verifying environment and system health..."
          echo "üíæ Memory usage: $(free -h | grep Mem)"
          echo "üíª CPU usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}')"
          echo "üñ•Ô∏è  GPU info:"
          nvidia-smi --query-gpu=name,memory.total,memory.used --format=csv,noheader,nounits 2>/dev/null || echo "‚ö†Ô∏è GPU info not available"
          
          # Test Python environment
          python -c "import sys; print(f'Python: {sys.version}'); import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU count: {torch.cuda.device_count()}') if torch.cuda.is_available() else None" 2>/dev/null || echo "‚ö†Ô∏è Python environment check failed"
          
          # Run basic tests (skip if memory is low)
          echo "üß™ Running basic tests..."
          local mem_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
          if [ "$mem_usage" -lt 75 ]; then
            if [ -f "test_comprehensive.py" ]; then
              python test_comprehensive.py || echo "‚ö†Ô∏è Some tests failed, continuing..."
            fi
            
            if [ -f "test_3d_model.py" ]; then
              python test_3d_model.py || echo "‚ö†Ô∏è 3D model test failed, continuing..."
            fi
          else
            echo "‚ö†Ô∏è Skipping tests due to high memory usage (${mem_usage}%)"
          fi
          
          # Quick fixes if needed
          if [ -f "quick_fixes.py" ]; then
            echo "üîß Applying quick fixes..."
            python quick_fixes.py || echo "‚ö†Ô∏è Quick fixes failed, continuing..."
          fi
          
          # Setup nnUNet directories if needed
          export nnUNet_raw="/app/nnunet/raw"
          export nnUNet_preprocessed="/app/nnunet/preprocessed" 
          export nnUNet_results="/app/nnunet/results"
          mkdir -p /app/nnunet/{raw,preprocessed,results}
          
          # Convert data to nnUNet format if script exists (skip if memory is low)
          local mem_usage=$(free | grep Mem | awk '{printf "%.0f", $3/$2 * 100}')
          if [ "$mem_usage" -lt 70 ] && [ -f "Dataset137_BraTS21.py" ] && [ -d "ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData" ]; then
            echo "üîÑ Converting data to nnUNet format..."
            python Dataset137_BraTS21.py || echo "‚ö†Ô∏è Data conversion failed, continuing..."
          else
            echo "‚ö†Ô∏è Skipping data conversion due to memory constraints or missing files"
          fi
          
          echo "‚úÖ Setup complete!"
          echo "üìã Available commands:"
          echo "  - Training: python scripts/train_3d.py --data_root ./ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData --debug"
          echo "  - Training (alt): python scripts/train_3d.py --data_root /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData --debug"
          echo "  - Inference: python scripts/inference_3d.py --help"
          echo "  - Environment check: python verify_environment.py"
          echo ""
          echo "üìÅ Data locations:"
          echo "  - Training data: /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-TrainingData"
          echo "  - Validation data: /data/ASNR-MICCAI-BraTS2023-GLI-Challenge-ValidationData"
          echo "  - Symlinks in repo: $(ls -la ${REPO_PATH}/ | grep ^l || echo 'None')"
          echo ""
          echo "üñ•Ô∏è  Container will stay alive. Connect with:"
          echo "    kubectl exec -it tsereda-brats-pod -- /bin/bash"
          echo ""
          echo "üìä Final system status:"
          echo "üíæ Memory: $(free -h | grep Mem | awk '{print $3"/"$2}')"
          echo "üíª Load: $(uptime | awk -F'load average:' '{print $2}')"
          echo "üìÅ Disk usage: $(df -h /app | tail -1 | awk '{print $3"/"$2" ("$5")"}')"
          
          # Mark setup as complete for readiness probe
          touch /tmp/setup_complete
          
          # Keep container running
          tail -f /dev/null
      volumeMounts:
        - name: git-repo
          mountPath: /app
        - name: brats-data-volume
          mountPath: /data
        - name: dshm
          mountPath: /dev/shm
      resources:
        limits:
          memory: 32Gi  # Maximum allowed for pods without controllers
          cpu: "16"
          nvidia.com/gpu: "1"
        requests:
          memory: 28Gi  # Slightly under limit for safety
          cpu: "12"
          nvidia.com/gpu: "1"
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - SYS_NICE
            - IPC_LOCK
      # Add liveness and readiness probes for better pod management
      livenessProbe:
        exec:
          command:
            - /bin/bash
            - -c
            - "ps aux | grep -v grep | grep -q tail || exit 1"
        initialDelaySeconds: 600  # Increased from 300s to 10 minutes
        periodSeconds: 60
        timeoutSeconds: 10
        failureThreshold: 3
      readinessProbe:
        exec:
          command:
            - /bin/bash
            - -c
            - "test -f /tmp/setup_complete"
        initialDelaySeconds: 120  # Increased from 60s to 2 minutes
        periodSeconds: 30
        timeoutSeconds: 5
        failureThreshold: 20  # Increased from 10 to 20
  volumes:
    - name: git-repo
      emptyDir:
        sizeLimit: 50Gi  # Increased from 20Gi to handle any temporary files
    - name: brats-data-volume
      persistentVolumeClaim:
        claimName: brats2025-1
    - name: dshm
      emptyDir:
        medium: Memory
        sizeLimit: 16Gi
  restartPolicy: Never
  terminationGracePeriodSeconds: 60  # Increased from 30
